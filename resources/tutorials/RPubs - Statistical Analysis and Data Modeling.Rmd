---
title: "Statistical Analysis and Modeling in R"
author: "[Student Data Labs](https://studentdatalabs.com), Vision Zero Innovation Lab"
output: html_document
---
In this demo, we'll be using R to do some statistical analysis and modeling. We'll be finding correlations, building models, evaluating models, doing some data exploration and cleaning. This tutorial is intended for intermediate to advanced R users, although beginners may also find it useful.

First, you need to download the open data from the Student Data Labs [Github page](https://github.com/StudentDataLabs/VisionZeroInnovationLab). From here, Download ZIP, after which point you need to tell R where to find the data. To do this - Select 'Session' along the top of RStudio, then 'Set Working Directory' and 'Choose Directory'. 

## Data Exploration

Install the package we need to create the quick data visualisation - ggplot2
```{r}
install.packages("ggplot2", repos = "http://cran.us.r-project.org")
library(ggplot2)
```


Read in the dataset, indicating the the columns are in the first row with header = True
```{r}
road <- read.csv("accidents_2009-2014_duplicates_mapping.csv", header = TRUE, stringsAsFactors = FALSE)
```

Create a histogram showing the number of road accidents by age
```{r}
ggplot(road, aes(Age.of.Casualty)) + # Initialise plot and set the x-axis to casualty age
    geom_histogram(binwidth=1, fill="red", alpha=0.75) + # Set width, colour and size
    labs(title="", x="Age", y="") + # Add a label for the x-axis, leave y-axis and title blank
    theme(axis.text = element_text(size=10, family="Helvetica")) # Set font type and size
```

Remove the variables we're not interested in for this model - Reference Number, Grid References, Lat, Long, Accident Date and Column Number. To check out each of the variables and what they mean, see the guidance.csv file
```{r}
road$Reference.Number <- NULL
road$Accident.Date <- NULL
road$Easting <- NULL
road$Northing <- NULL
road$Latitude <- NULL
road$Longitude <- NULL
road$Col.Number <- NULL
```


## Correlation

In this practical demo of correlation, a core aspect of statistics - we'll find out the correlation between Casualty Severity and Number of Vehicles, as well as the correlation between variables. A quick reminder - a negative result indicates a negative correlation, while a positive result indicates a positive relationship. In the next step we'll be investigating Casualty Severity. This step should not be used as a substitute for signficance tests, which we'll move onto next in the Linear Regression section.
```{r}
cor(road$Casualty.Severity, road$Number.of.Vehicles)
```

But what if we want to find out and rank the correlation between variables? First, we need to install the necessary packages and build the correlation matrix
```{r}
install.packages("reshape2", repos = "http://cran.us.r-project.org")
install.packages("scales", repos = "http://cran.us.r-project.org")
library(reshape2)
library(scales)

Correlation <- cor(road)
```

Melt into long format. This is where the 'melt' and 'reshape' two packages come in
```{r}
Correlation_Melt <- melt(Correlation, varnames=c("x", "y"), value.name="Correlation")
```

Order according to correlation
```{r}
Correlation_Melt <- Correlation_Melt[order(Correlation_Melt$Correlation), ]
```

Display the melted data, which will rank the correlation between variables
```{r}
Correlation_Melt
```

You can create a heatmap showing the correlation between variables. When you create the plot in R, the x-axis may be muddled. To correct this, select 'Zoom' at the top left and widen the screen to see all the variables
```{r, fig.width = 19, fig.height = 7}
ggplot(Correlation_Melt, aes(x=x, y=y)) + # initialise the plot and set axes
  geom_tile(aes(fill=Correlation)) + # Draw tiles and fill colour based on correlation
  scale_fill_gradient2(low="red", mid="white", high="blue", guide=guide_colorbar(ticks=FALSE), limits=c(-1,1)) + # Create a three tier gradient with a diverging colour scale and set the limits
  theme_minimal() + # Use minimal theme so there are no extras in the plot
  labs(x=NULL, y=NULL) # Remove labels of x and y axes
```

## Linear Regression

What is Linear Regression?
Linear regression is one of the most popular prediction methods for data scientists and statisticians. If you are looking to predict a numerical quantity like price or blood glucose levels that is continuous, then linear regression is a good place to start. You can find our more about linear regression by following [this introduction](http://www.statisticssolutions.com/what-is-linear-regression/). There are many models to choose from, which means carefully selecting which is best for the problem as well as the data you're working with. To find out a bit more about statistical model building visit this [flowchart](http://www.datasciencecentral.com/profiles/blogs/how-to-choose-a-statistical-model).

Build the linear model, with Number of Casualties as our dependent variable and age as the single independent variable. Both are continuous. This is done using the lm function
```{r}
linear_model <- lm(Number.of.Casualties ~ Age.of.Casualty, data = road)
```

Print the results of the model. To find out how to interpret the results, you have a number of options. First you can use the help function help(summary.lm) or try online. The following [link](http://blog.yhat.com/posts/r-lm-summary.html) gives a nice overview.

```{r}
print(summary(linear_model))
```


## Logistic Regression

Logistic Regression is another way of modeling data. However, when data is categorical and not continuous (e.g. Casualty Severity, which has three levels) then generalized linear models are better. To find out more about logistic regression, [this link](http://ww2.coastal.edu/kingw/statistics/R-tutorials/logistic.html) provides a good intro.

You can run logistic regression by using the function glm, rather than linear regression's lm
```{r}
logistic_model  <- glm(Casualty.Severity ~ Weather.Conditions + Road.Surface + Lighting.Conditions + Sex.of.Casualty + Type.of.Vehicle, data = road)
```

To run all variables, a shorter version of the code can be used:
```{r}
logistic_model_2 <- glm(Casualty.Severity~., data = road)
```

Again, let's print the results of our second linear model
```{r}
print(summary(logistic_model_2))
```

To compare the two regression models visually we need to install the 'coefplot' package
```{r}
install.packages("coefplot", repos = "http://cran.us.r-project.org")
library(coefplot)
```

We can plot the coefficients of one of the linear models - in this case the second linear model for Casualty Severity
```{r, fig.width = 10, fig.height = 4}
coefplot(logistic_model_2)
```


Using multiplot, we can compare the two logistic models. Each coefficient is plotted as a point with a thick line representing the one standard error confidence interval and a thin line representing the two standard error confidence interval. If the two standard error confidence interval does not contain 0 it is not statistically significant
```{r, fig.width = 12, fig.height = 6}
multiplot(logistic_model, logistic_model_2)
```


## Summary
That's it! We've created a quick chart, found out the correlation between variables and run linear and logistic regressions on the road casualty dataset.

![](https://studentdatalabs.files.wordpress.com/2016/01/newlogo4-e1460235034568.png)
